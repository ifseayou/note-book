#### 1：开篇词

欢迎各位大佬怀揣不耻下问，不耻下听的心态来到这场分享，下面由奔尘给大家分享一下自己最近读的书，ddia ,全名叫做：design data-intensive application 直译为：设计数据密集型应用；或者叫做，数据密集型应用的设计。

##### 过度：

我相信在场的各位一定历经过这样的场景：春节档档期一下子上映了很多场电影，  @现场观众，一场电影要不要去看，你是如何决策的？

对于我来说呢，通常都是先看一下豆瓣评分，如果高的话，就买票入场，对吧，所以为什么选择分享这本书，那就不得不说下这本书

#### 2：关于ddia的溢美之词

可以看到，这本书的评价惊人的高，居然达到了 9.7分的高分，有的同学可能觉得9,7分并不是一个很高的分数，来看下面这部是个码农都知道的书《算法导论》，这本书的评分是多少呢？大家猜一下......  

9.3 分，当然这是一个很高的分数，但是ddia 比这个高度还要高 0.4分；有的同学可能还是不能很直接的get到这本书的魅力，OK，我们来和豆瓣电影评分类比一下，要知道豆瓣中电影评分最高的也就是9.7分，也就是大名鼎鼎的，我相信在做的各位都看到《肖申克的救赎》。

<img src="./img/ddia/01.jpg" width = 100% height = 70% alt="图片名称" align=center />

这本书不仅仅是收到了很多读者的追捧，而且也不很多互联网公司青睐，甚至把他写到了面试的大纲里，比如说下面这家公司：

可以看到上面的网址的域名是 Byte Dance

**所以结论来了，DDIA , 你值得拥有**。

#### 3 关于作者

接下来，我们一起来看下这本书的作者，按照 PPT 。

#### 4 整书大纲

下面是整书的一个脉络：分为**3**个部分12个章节，

三部分：

* **数据系统的基石 **： 主要讲述了数据系统底层的一些概念，无论是单机上的单点数据系统，还是分布在多机器上的分布式系统。这个讨论的范围是 <u>单机或者多机器，区别于第二部分仅谈论多机器上的分布式系统</u>，
  * **1：可靠性、可扩展性、可维护性**  在开发一个应用的时候，必须要满足各种需求才能称之为有用，除了功能需求（也就是能够实现什么功能）还需要一些非功能需求，也就是通用属性，比如说 [可靠性](意味着即使发生故障，系统也能正常工作)、[可扩展性](意味着即使在负载增加的情况下也有保持性能的策略)、[可维护性](有许多方面，但实质上是关于工程师和运维团队的生活质量的)）
  * **2：数据模型与查询语言**  这个是从使用者的角度出发，<u>注意这个视角很重要</u> 描述数据录入数据系统的格式，已及如何将存入的数据取出来。讲述关系模型，文档模型，图模型。比如说对于关系型数据库来说，使用DML = 数据模型；DSL = 查询语言 ，这其实是一种声明式的查询语句。这一章节阐述了关系模型的各个挑战关系模型最后又落败的，至今关系模型依然数据模型的王者。[1](对于高度相联的数据，选用文档模型是糟糕的，选用关系模型是可接受的，而选用图形模型（参见“[图数据模型](https://vonng.gitbooks.io/ddia-cn/content/ch2.html#图数据模型)”）是最自然的.)
  * **3：存储与检索**  这个是从数据系统的角度出发，描述数据系统如何存储我们录入的数据，已及，在我们需要这部分数据，存储系统如何精准、快速的定位到目标数据。这里注意区分 2章节 和 3章节  
  
  * **4：编码与演化**  随着时间推移，数据系统由于功能的迭代，需要对初始涉及的数据模型（schema) 进行更改，那么如何处理数据模型的前后兼容问题，就是这个章节要讨论的问题。
  
* **分布式数据** ：多台机器参与数据的存储和检索，数据系统所面临的一些挑战，
  * **5：复制** ： 同一份数据，多个拷贝
  * **6：分区** ： 同一份数据，分割成多块
  * **7：事务** ： 主要介绍 事务，ACID，隔离级别等内容，个人觉得这部分内容是重点也是难点。
  * **8：分布式系统的麻烦** ： 在极端情况下，分布式系统黑暗的诸多问题，看完这一章节，你会觉得你所处于的环境真的是太幸福了
  * **9：一致性与共识** ：分布式数据系统如何去实现一致性和达成共识，从而避免类似于 brain split  的问题，这一章节会讨论在构建容错分布式系统的时候使用到的 算法和协议（比如Raft、Paxos、ZAB），一定会让你有所收货。[关于一致性协议1](https://baijiahao.baidu.com/s?id=1693824822611080380&wfr=spider&for=pc) ，[关于一致性协议2](https://blog.csdn.net/demon7552003/article/details/86657767)
  
* **派生数据**：主要讨论衍生（派生）数据：所谓*衍生数据* 是以输入数据输出新的数据，输出是衍生数据（derived data）的一种形式 ，流处理和批处理都会产生衍生数据。
  * **10：批处理**  🤣 
  * **11：流处理**   🤣
  * **12：数据系统的未来** 🤣

🎈**过度**🎈：以上呢，就是整本书的一个简短的概括，下面的内容就是我基于书中的内容做的一些总结，已及自己的一些启发

#### 5 计算密集与数据密集型应用区分

下面对应用程序的简要分类：

* 首先是计算密集型应用，这类应用的瓶颈是算力，比如进行气象预测，对于这类应用我们处理的方式就是不断的提升计算机的算力，比如增加cpu  的核数增加内存等
* 再有就是数据密集型，这类应用的瓶颈是：
  * 数据量
  * 数据的复杂性
  * 数据的变更速度

对于数据密集型应用，我们通常会使用标准的组件来处理：

- 存储数据，以便自己或其他应用程序之后能再次找到 （**数据库（database）**
- 记住开销昂贵操作的结果，加快读取速度（**缓存（cache）**
- 允许用户按关键字搜索数据，或以各种方式对数据进行过滤（**搜索索引（search indexes）**
- 向其他进程发送消息，进行异步处理（**流处理（stream processing）**
- 定期处理累积的大批量数据（**批处理（batch processing）**

#### 6 第3章存储与检索（脉络）

那么在第一部分，第三章节，是存储与检索的内容，也就是说：数据库在最基础的层次上完成的2件事情：

* 当你把数据交付给它的时候，它如何将数据存储起来
* 当你向数据库索要数据时，它如何将数据返回给你

由于事务性负载和分析性负载的存储引擎之间存在着很大的差异，这两类的存储引擎我们分开来描述，

**在事务处理方面**：

* 日志结构存储引擎  ；从最简单的数据库实现 append-log  到 [LSM](日志结构合并树) 树的演化历程。
* 面向页面的存储引擎 ，典型的比如B-Tree

在**分析性存储引擎方面**，我们谈谈

* 数据仓库
* 星型模型&雪花模型
* 列存储

#### 7 无索引日志

我们来看下 **世界上最简单的数据库** 是如何实现的，

* 首先来一个插入操作
* 再来一个更新操作
* 最后，来一个get 操作

那么这个最简单的数据库底层是如何进行数据的摆放或者是存储的呢？看可以看到就是一个非常简单的追加【**顺序写入速度>>随机写入**】，这**简直不是简单，甚至可以说是简陋** 但是正是由于这种设计使得写入变的非常的高效，代价就查找的开销是 O（N） ，同时也带来一个问题，O（N）的复杂度，这意味着如果数据量增加一倍，查询响应时间将会增加一倍。也就是说查询时间和数据量之间的关系是线性相关的。所以我们需要**更快的得到目标结果**，那么如何去提升数据的查找效率？

#### 8 如何提升查找效率？

当我们还在上小学的时候，可能也面临过类似的问题，假设说现在有2个小学生，忘记了 **囧** 字怎么写，想要用新华字典查询一下：

* @小明 同学使用的是一本没有目录的字典  （比如说康熙年代出版的字典，就是属于没有目录的字典）

* @流川同学 使用的是一本有目录的字典（现代新华字典）

  那么谁最后能更快的获知 `jiong` 字的写法呢？上过小学的都知道@流川同学有较大的概率最快获取到 `joing`字的写法。

可以发现现代字典的特征就是都会有一个目录，这个目录是在**原始数据之外维护的额外的数据**，正是由于目录的存在，使得@流川同学能够更快的获取到目标数据。其实这个目录，其实就相当于英文中的 index , 而 index  就是索引，所以我们可以得到一个结论：

> 索引 是在原始数据之外维护的额外的数据，索引 可以加速数据访问

🎈**过度**🎈

由于需要在原始数据之外额外维护一份数据，这就无形增加了空间复杂度，在计算机领域中，时间和空间就像鱼和熊掌一样，不可兼得，降低时间复杂度的方式就**用空间换取时间**； 可以说这个问题在计算机领域是一个绕不开的话题，如何去提升查找效率这个问题的另外一种问法是：**给我一个更低的时间复杂度**的实现，那么常见的比O（N）  还低的时间复杂度就是 O（1）,O (logN ) 两个，O（1）的时间复杂度，我们很容易就会想到哈希表，因为哈希表的时间复制度就默认为O（1）的。

#### 9 内存中构建hash索引

那么对于存储于磁盘中的数据，我们在内存中维护一个HashMap，维护key和value 的偏移量，这样一来，我们就能够迅速的定位到目标数据，比如我们想要find key = 42 的数据，通过查询内存中的HashMap表，获得偏移量64 ，所以可以直接定位到数据，而不在需要从头开始遍历。

随着我们不断的在文件末尾追加文件，磁盘中的单个文件也会越来越大，甚至单个文件可能吃掉整个磁盘的存储。所以，**如何用有限的存储存储更多的数据？** 也就是说如何避免磁盘的空间的消耗？

#### 10 压缩与分段合并 & hash索引的局限性

我们解决的方案是：

* 分段存储：也就是说当追加文件的size达到了一定的阈值之后，我们重新写入写的文件

* 压缩：丢弃重复的键，保留每个键的最新值

比如PPT中原本12个键 压缩之后之后3个键，整个文件的size降低。

**如何进一步改进？** 在执行压缩的同时，可以将压缩之后的**段合并**。如 Data file segment 1 和 Data file Segment 2 在压缩了之后，进行了一个合并操作，得到了 Merged Segment 。比如mew 这个键，按图说明即可。

压缩和合并对用户是没有感知的，由后台进程完成，在合并的时候由旧的段文件提供读写请求，在合并完成之后，读写请求转化为新的合并后的段。

那么由于hash表本身的特性，也会导致我们构建的哈希索引有一定的局限性，比如：

* 哈希表是存在于内存中的
* 范围查询是软肋

那么如何突破哈希表的局限性，寻找更好的索引结构？

#### 11 SSTable 排序字符串表

这个问题的答案是：排序字符串表，也就是**SSTable**, 也就是：在段文件中，对键值对的序列排序。比如上图中，对于已经排好序段文件1，段文件2 ，段文件3 ，进行压缩和合并，而且呢，在合并之后呢，仍然需要合并之后的段文件时有序的，所以我们需要一个合适的排序算法：**那么这个排序算法是什么呢？** *归并排序*  ； **有谁了解过这个算法是谁发明的吗？** *冯诺依曼*。OK。这个算法的优势是什么？merge sort 的优势呢就在于 内存在小于被排序文件大小的时候，仍然可以将排序完成。

使用SSTable 可以有效的突破内存限制 和 解决范围查询的问题。如下图中我们查找，handiwork 的过程，可以发现不是在内存中保存所有键的索引，由于SSTable维护了顺序关系，我们的索引以稀疏索引的方式存在于内存中。同时，可以支持范围查询。

#### 12 LSM 日志结构合并树

在前面的讲述中，我们默认了落盘段文件是有序的，在落盘写入段文件之前，**如何按键排序**？考虑到效率问题，最初的的写入一定是在内存中的，到达一定的时间阈值或者是内存阈值的时候，在进行落盘形成 SSTable，那么内存中**选择什么样的数据结构？**

* 内存表，**为什么是AVL-Tree ？** 
  * 也就是平衡二叉树，因为平衡二叉树本身就是二叉搜索树，而二叉搜索树中序遍历就是顺序结构，可以直接落盘形成SSTable；
  * 由于平衡特性呢，可以保持树的结构，而不是退化成链表，使得查询的时间复杂度为 O（logN）, 而且对于新加入的数据，平衡二叉树通过左旋或者右旋的方式实现顺序和自平衡。
* 落盘
* 先请求内存，在查询磁盘段
* 压缩和合并
* 防止数据库崩溃

那么使用这种结构的组件有哪些呢？

* [Cassandra](卡桑德拉，Apache Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于改善电子邮件系统的搜索性能的简单格式数据，集Google BigTable的数据模型与Amazon Dynamo的完全分布式架构于一身)
* Bigtable
* HBase
* Elasticsearch

* [Solr](和ES一样是一个企业级的搜索引擎)

**这种先内存排序，在落盘排序的这种结构，就是LSM（Log-Structure Merge Tree 日志结构合并树）的结构。** 阿里自研实时数仓工具hologres 使用 的也是这种结构。

#### 13 面向页存储引擎

接下来我们介绍另外一种存储引擎：面向页面的存储引擎，比如B 树，B树会将数据库分解为固定大小的块或者是页面，传统大小为4K而且一次只能读取或者写入一个页面，对比下LSM，按照PPT。

来看下B树中的一个页面，并且看看面向页面的存储引擎是如何查询数据的，按照PPT。

分支因子：**在B树中一个页面中对子页面的引用数量**。

面向页面的存储引擎发展的已经非常成熟了，伴随着上世纪70年代关系型数据库的发展至今。

#### 14 向页面添加元素

如何向B树中增加一个数据，按照PPT。

#### 15 比对LSM树 和 B树

最后我们来一起对比一下LSM树和B树，也及时面向日志的存储引擎和面向B树的存储引擎。按照PPT连线即可。

#### 16 OLTP&OLAP 和 数据仓库

数据库在历史中主要为两种系统提供支持

* 在线事务处理系统
* 在线分析系统

下图表中对比了两者之间的区别，起初的数据库，能够同时应对以上两种查询的情况，无论是OLTP类型的查询，还是OLAP类型的查询，单一的数据库的表现的都很好，也就是说：**<u>也就是说两者是一家的</u>**。 OLAP通常会要求 **高可用** 与 **低延迟**，为了保证业务系统的稳定运行，所以DBA会密切关注他们的OLTP数据库，他们通常不愿意让业务分析人员在OLTP数据库上运行临时分析查询，因为这些查询通常开销巨大，会扫描大部分数据集，这会损害同时执行的事务的性能。可以见得，OALP和OLTP 这对亲兄弟发生了矛盾，矛盾会最佳解决方案就是分家。在二十世纪八十年代末和九十年代初期，渐渐地很多公司有停止使用OLTP系统进行分析，而是在单独的数据库上运行分析。这个单独的数据库被称为**数据仓库（data warehouse）**。因为最初的数据仓库是从关系型数据库中独立出来，只存储关系数据，而且是面向数据分析，BI（商业智能）的，只是到了后来随着大数据时代的到来，  数据仓库才慢慢变的越来越像 **数据湖** （就是各种数据都跑往数据仓库里面塞）。

* 数据湖：是指使用[大型二进制对象](https://zh.wikipedia.org/wiki/二進位大型物件)或文件这样的自然格式储存数据的系统[[1\]](https://zh.wikipedia.org/wiki/数据湖#cite_note-1)  ，数据湖可以包括[关系数据库](https://zh.wikipedia.org/wiki/关系数据库)的[结构化数据](https://zh.wikipedia.org/wiki/数据模型)(行与列)、半结构化的数据([CSV](https://zh.wikipedia.org/wiki/逗号分隔值)，日志，[XML](https://zh.wikipedia.org/wiki/XML), [JSON](https://zh.wikipedia.org/wiki/JSON))，非结构化数据 (电子邮件、文件、PDF)和 二进制数据(图像、[音频](https://zh.wikipedia.org/wiki/數位音訊)、视频)
* 数据沼泽：**数据沼泽** 是一个劣化的数据湖，用户无法访问，或是没什么价值。饕餮

又或者说，**数据湖是下一代数据仓库**

从OLTP数据库中提取数据，转换成适合分析的模式，清理并加载到数据仓库中，因此数据仓库包含公司各种OLTP系统中所有的只读数据副本。下图是一个简要的示意图：

#### 17 数据仓库系统组件

我们来看一些比较出名的商业数据仓库系统，尽管他们是冠以出名的商业数据仓库系统，但是其中商业两个字可能是太贵，导致我们大多数从事数据仓库相关工作的人，其实并不知道，

* SQL - Server   使用两套不同的存储和查询引擎来应对OALP和OLTP环境
* Teradata       天睿
* Vertica          维蒂卡
* SAP HANA    SAP  汉那
* ParAccel        帕加速

相对而言，我们更喜欢免费的开源产品，下面是一些SQL-on-Hadoop 项目：

- Hive-SQL
- Spark-SQL
- Flink-SQL
- Presto          2013-FaceBook
- Druid            德鲁伊
- Kylin
- Impala

#### 18 雪花模型

在OLTP系统中，可用的数据模型很丰富，比如大类上分为

* 关系模型
* 新的非关系模型，No-SQL模型
  * 文档数据库模型
  * 图形数据库模型

相对于OATP系统来说，OLAP系统的数据模型多样性就少的多，数据仓库大多使用一样的公式化模型：**<u>星型模式|星型模型(也叫维度建模)</u>** 如下图：

* 模式的中心是一个所谓的事实表，事实表的每一行代表在特定时间发生的事件（这里，每一行代表客户购买的产品）
* 事实表中的一些列是属性，例如产品销售的价格和从供应商那里购买的成本（允许计算利润余额），通常是数字等可统计指标
* 事实表中的其他列是对其他表（称为维表）的外键引用，由于事实表中的每一行都表示一个事件，因此这些维度代表事件的发生地点，时间，方式和原因
* 事实表格有100列以上，有时甚至有数百列，快手他们宽表列长达1000+列，
* 星型模型进一步的扩展是 雪花模型，也就是基于维度表进一步拆分。

当表关系可视化时，事实表在中间，由维表包围；与这些表的连接就像星星的光芒，所以这模式被命名为：“星型模式”。

#### 19 列式存储

在前面的存储结构中，我们介绍了

* 基于日志的存储
* 基于页面的存储

然而，典型的数据仓库查询一次只能访问4个或5个列，如果使用行存储的话，面向行的存储引擎仍然需要将所有这些行（每个包含超过100个属性）从磁盘加载到内存中，解析它们，并过滤掉那些不符合要求的条件。这可能需要很长时间。面向列的存储背后的想法很简单：不要将所有来自一行的值存储在一起，而是将来自每一列的所有值存储在一起。如下图：按图索骥即可。

大家可以观察到红色框选出来的值序列，他们是重复数据，而**重复数据是压缩的好兆头**。我们根据列中的数据，可以使用不同的压缩技术来进一步降低对磁盘吞吐量的需求，在数据仓库中特别有效的一种技术是位图编码，如下图：

#### 20 存储与检索 总结

我们耗费了相当大的篇幅来讲述了第三章：存储与检索的内容，接下来我们做一个小的总结。

🎈**过度**🎈

如何你真的删了库，那么你就得跑路！但是如果维护有数据副本，可能就不再需要跑路了。

#### 21 复制

接下来是第5章的内容，这章节的内容主要是复制，所谓复制呢，就是**<u>同一份数据保留多个副本</u>**。 复制数据的原因呢

- 使得数据与用户在地理上接近（从而减少延迟）
- 即使系统的一部分出现故障，系统也能继续工作（从而提高可用性）
- 扩展可以接受读请求的机器数量（从而提高读取吞吐量）

真正的麻烦在于如何**处理复制数据的变更** 。本章主要讨论三种变更复制算法：

* 单主复制
* 多主复制
* 无主复制

当存在多个副本时，会不可避免的出现一个问题：如何确保所有数据都落在了所有的副本上？

🎈**过度**🎈

当存在多个副本时，会不可避免的出现一个问题：如何确保所有数据都落在了所有的副本上？我们来看一个非常普遍且常用解决方案：**<u>单主复制</u>**

#### 22 单主复制

来具体看一个场景，更换新的用户头像的实例：按照PPT

总结一下单主复制符合以下的特点：

* 多个副本中only 一个设置为leader,其他是flower
* leader 接受读请求和写请求，follower只接受读请求
* follower从leader拉去日志，更新本地数据库副本

这种复制模式是很多关系型数据库内置的功能,比如说：

* PostgreSQL(9.0之后)，
* MySQL，
* SQL Server，
* 文档型数据库 MongoDB，非关系数据库

其实基于领导者的复制不局限于数据库，像一些高可用的分布式MQ也也再用，比如说常见的 

* Kafka 

* RabbitMQ

🎈**过度**🎈

接下来呢，我们讨论复制系统的一个重要细节：复制是**同步（synchronously）**发生还是**异步（asynchronously）**发生

#### 23 同步 / 异步

如下图：

* 用户id为1234的用户向主库提交数据变更请求
* 主库将数据变更同步给从库1，并且等待从库1的响应，这里从库1复制的方式是同步
* 主库将数据变更同步给从库2，但是不等待从库2的确认，这里从库2的复制方式是异步

这种配置方式有时也被称作是半同步。我们来一起看下同步和异步复制的优劣势：

* 同步复制能够保证数据可靠性，但是如果从库迟迟不能响应主库，主库就不能接收新的读写请求
* 异步复制的优点是，即便从库落后了，主库也可以继续处理写入请求

我们再来看一下设置新从库的步骤：

* 获取某个时刻主库的一致性快照
* 将快照复制到从库节点
* 从库连接主库，拉取快照之后发生的数据变更。拉取快照之后的变更往往 快照和主库复制日志关联，记录关联关系的不同的数据库实现有着不同的名称：
  * PostgreSQL 的叫做**日志序列号（log sequence number, LSN）**
  * MySQL将其称为 **二进制日志坐标（binlog coordinates）**

🎈**过度**🎈 接下来我们说一下如何进行故障节点的处理，从库失效的问题很好解决，从库在重新和主库建立连接之后，可以从日志知道最后一个失败的事务。然后开始追赶主库。我们重点开下主库失效如何处理。

#### 24  处理故障节点

**主库失效如何处理？**

* 确认主库失效，
* 选择一个新的主库，**<u>让所有的副本达成一致意见（共识问题）</u>**
* 重新配置新的主库，并且启用新的主库

一些挑战：

* 如果使用异步复制，发生的数据丢失问题，GitHub事故，MySQL主库挂掉了，新的主库在开始的时候大都是美好的
* 脑裂的情况，设置新的主库之后，老的主库又一次活过来了，可能会存在两个主库的情况，同时接受写入，可能会导致数据损坏，解决的方案可能是，发送kill 去干掉一个主库
* 宣告主库死亡的阈值，主库在宣告死亡前，超时时间的设置。主库失效时，太长，意味着恢复时间长，太短，就会发生不必要的切换。

**基于主库的复制底层是如何工作的？**

* 基于语句的复制，有非确定性函数、自增列的问题

* 传输预写式日志（WAL），日志包含所有数据库写入的仅追加字节序列，可以将其发给从库，比如说PostgreSQL 、Oracle
  缺点是数据过于底层，WAL包含哪些磁盘块中的哪些字节发生了更改。这使复制与存储引擎紧密耦合，对数据库版本不友好，这对运维升级数据库带来了一定的困难。

* 逻辑日志复制（基于行），也即复制日志和存储引擎存储的日志采用不同的格式，这种复制日志被称为逻辑日志。

  * 对于插入的行，日志包含所有列的新值。
  * 对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。
  * 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。

  这样的逻辑日志，而使领导者和跟随者能够运行不同版本的数据库软件甚至不同的存储引擎。

* 基于触发器的复制，触发器能够实现，在数据库系统中发生数据更改（写入事务）时自动执行的自定义应用程序代码，不同于数据库系统实现的复制。



#### 26 事务

其实很早就接触事务这个概念，关于事务呢，看网上的文章动不动就把转账的的例子拿出来，更坑的时候有的压根就没有讲明白对吧，概念也背的烂熟，也知道事务的4大特性ACID (也就是原子性、一致性、隔离性、持久性)，所谓事务就是 **<u>事务要不就执行成功，要不执行失败，只有这2种状态</u>  **，但是这么些年从来没有思考过，为什么要有事务？他解决了什么样子的问题和痛点。那么我们带着这样的一个问题来回顾一下事务起源：

这里有一个名为猪小明程序员抱着自己的电脑在疯狂的写代码，开发应用程序，其中应用程序需要透过网络和数据库进行数据的存储和获取，数据库软件是依托于什么？OK，我们把操作系统画出来，在操作系统的底层呢，是一些计算机硬件，比如说，存储介质，磁盘，缓存cache,RAM ,ROM，CPU，主板等等。在整个场景中呢，很多事情都有可能出错，比如：

* 网络中断，客户端和应用程序服务之间，服务和数据库之间
* 数据库软件本身挂掉了，硬件发生故障（硬件故障是很高的，频盘在进行大量的读写之后失效的概率是很高的，IDC数据中心的物理环境的要求是很苛刻的，为了降低温度空调不够用，甚至把数据中心搬到山洞里，比如阿里在贵州云南的IDC，地板使用静电地板，每个房间入口的挡鼠板比膝盖还高。
* 应用程序在进行写入的时候，写到一半，自己崩溃了。
* 多个客户端同时操作数据库，覆盖彼此的更新。
* 客户写到一半的数据，被另外一个客户读取到。
* 客户之间的竞争导致的令人惊讶的错误。

所有的这一些都需要应用程序的开发者，猪小明去解决，其实这个工作量是巨大的，应用开发应该专注于业务，而不是通用问题的处理，所以对上面的问题的处理，应该放在下层处理，也就是说留给数据库去处理。

所以为了**<b>简化应用编程模型</b>** ，事务诞生了。通过使用事务，应用程序可以自由地忽略某些潜在的错误情况和并发问题，因为数据库会替应用处理好这些。

1974年的时候，IBM的圣荷西研究中心发布了第一款提供优秀的事务处理能力的关系型数据库，看PPT图介绍。

在我们已经习惯了事务的时候，我们就是觉得事务是理所当然的，他是天然就存在的，然而并不是，了解事务出现的历史，我们可以发现事务不是自然存在的，是我们的计算机先驱们为了解决一揽子问题，提供的一种解决方案。

#### 27 ACID

前面我们也提到了，谈及事务，必谈事务的 4大特性，ACID  ；解释这四个特性，需要说清楚3个问题：

* ACID 四个特性分别指的什么
* 这个四个特性之间的关系
* 和事务的关系

**😁ACID 分别指的是什么呢？谁来回答一下**

A ： 原子性，在没有原子性的时候，如果有多次更改，但是更改发生一半的时候发生了错误，应用程序此时很难判断哪些更改生效了，哪些没有生效。如果有了原子性，应用程序可以确定的知道在发生错误时，所有更改都没有生效。**<u>能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力</u>**，可以理解为**可终止性**。**<u>没有原子性，错误处理就会变的很复杂</u>**。

区别于线程的原子操作：多线程中的原子操作描述的是：如果一个线程执行一个原子操作，意味着另外一个线程无法看到该原子操作的中间结果。而这个特性在ACID中是 *I* 来描述的。

D ：持久性，持久性是事务得一个承诺，也即事务完成后，即便发生硬件故障或者数据库崩溃，写入的任务数据也不会丢失。一致性过去一般被认为写入了非易失性存储介质。

C：一致性。这是一个一词多意的词，用行话来说，是这个词被重载了

:one: 有别于副本一致性，比如在单主复制的模式下，采用异步复制的方式，收敛最终一致。

:two: 还有大家有可能会听过一致性hash （一致性散列）那是一种为了避免重新分区带来的复杂度提高的一种解决方案。

:two: CAP定理中，C指的是线性一致性。

在事务中，一致性是指：**对数据的一组特定陈述必须始终成立**，即为*不变量*，在会计系统中，所有账户整体上必须借贷相抵。原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。

I：隔离性，**竞争条件下，同时执行的事务是相互隔离的**，两个客户之间的竞争状态同时递增计数器的 图述。**缺乏隔离性，就会导致并发问题**

<img src="./img/ddia/02.jpg" width = 90% height = 70% alt="图片名称" /> 

4个特性之间的关系，一致性是目的，原子性、隔离性、持久性手段。

如果说数据库能够提供事务的能力，那么就具备ACID4个特性，如果具备这4个特性，也就表明有事务能力，也就是说事务和4大特性形成充分必要条件

####  单对象操作和多对象操作

**单一对象操作**，所谓单对象操作中的对象指的是数据库中被修改的对象，比如你正在向数据库写入一个20KB的Json文档，可能会发生下面几个场景：

* 在发送第一个10KB之后，网络连接中断，数据库是否存储了不可解析的10KBJSON片段
* 在数据库正在覆盖的磁盘上的前一个值的过程中电源发生故障，是否最终将新旧值拼接在一起？
* 如果另一个客户端在写入过程中读取该文档，是否会看到部分更新？

这里的 JSON对象，就是单一对象，单一对象是相对于多对象而言的，待会我们会谈及到多对象。为了针对以上的问题，存储引擎会在单个对象上提供原子性和隔离性，如此一来：

* 原子性通过WAL日志来实现崩溃恢复
* 使用每个对象的锁来实现隔离（每次仅仅允许一个线程访问对象）

**CAS**，为了防止多个客户端同时写入同一个对象时的更新丢失，除了单对象操作，还有就是CAS（Compare-and-set) ，也就是当值没有并发并其他人修改的时候，才允许执行写入操作。

CAS操作和单对象操作，被称作是轻量级事务。事务通常更多的强调 ： 将多个对象的多个操作合并为一个执行的单元的机制。

**何为多对象？** 在操作数据库时，需要协调写入几个不同的对象：

* 关系模型中，一个表中的行对另外一个表的外键引用。你得确保外键是最新的，可用的
* 在字段冗余的场景中，单个字段在多处被存储，你得保证这几处是同步的
* 二级索引的数据库中，数据更新的时候，二级索引也需要更新

在这种情形下，需要使用事务来进行处理。

关于分布式事务：分布式事务的目的是多个节点达成共识/一致；进一步需要使用共识算法去实现原子提交，这些算法有，2pc[^i]，帕斯卡，zab，raft等

> [^i]: 二阶段提交，能够确保几个不同的系统一起提交或放弃。区别于2PL[^ii]   

🎈**过度**🎈，接下来我们会讲述隔离级别，在讲述隔离级别之前，明确两点：

:a: 隔离级别是在事务的4大特性之一的隔离性上划分的一个等级，隔离级别是事务的4大特性之一；其中SQL标准的事务隔离级别包括：

* 读未提交（read uncommitted）
* 读提交（read committed）
* 可重复读（repeatable read） 
* 串行化（serializable ）

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

:one: “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念。

:two: 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。

:three: 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。

:four: “串行化”隔离级别下直接用加锁的方式来避免并行访问。

:b: 隔离级别最高是可序列化，表示同一时间只能有一个事务，隔离级别和性能之间是一个负相关的关系，也就是说隔离级别越高，数据一致性的保证越好，但是性能越差

所以说，隔离级别是数据一致性和服务性能的一场博弈。为了实现更优的性能，我们需要较弱的隔离级别。下面介绍一些弱的隔离级别：

#### 28 读已提交

最基本的弱隔离级别是，读已提交，它提供了两个保证：

* 从数据库读时，只能看到已提交的数据（没有**脏读（dirty reads）**）。
* 写入数据库时，只会覆盖已经写入的数据（没有**脏写（dirty writes）**）。

另外补充：读未提交：

* 可以防止脏写
* 但是不能够防止脏读

下面是一个没有脏读的例子：可以看到在这个例子中直到用户1提交了之后，用户2才看到提交之后的值x=3,而在这之前用户3只能看到x=2。

<img src="./img/ddia/03.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

那么为什么要防止脏读呢？主要是下面两个原因：

:one: 如果事务需要更新多个对象，脏读取意味着另一个事务可能会只看到一部分更新。比如说下面这个电子邮件的例子。事务还没有提交，但是用户2看到了未读邮件，可是未读邮件的数量却还是旧值。

<img src="./img/ddia/04.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

:two: 数据库允许脏读，那就意味着一个事务可能会看到稍后需要回滚的数据，即从未实际提交给数据库的数据。比如下面的例子中红色标记的位置读到了未提交的数据，但是后面事务回滚了。

<img src="./img/ddia/05.jpg" width = 80% height = 70% alt="图片名称" align=center />

没有脏写，在写入数据库时，只会覆盖已经写入的数据，也就是说两个事务同时更新数据库中的对象，先前的写入没有提交，后面的写入覆盖这个尚未提交的值，这就是脏写。在**读已提交**的隔离级别上运行的事务必须防止脏写，通常是延迟第二次写入，直到第一次写入事务提交或中止为止。下面是脏写发生的后果，看图即可。 

<img src="./img/ddia/06.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

发票属于Alice; 销售属于Bob。

#### 29 实现读已提交

读已提交是一种非常Fashion的一个隔离级别，有很多数据库软件将读已提交设置为默认的隔离级别，比如

* Oracle 11
* PostgreSQL 
* SQLServer 2012 

那么如何实现

:one: 无脏写保证：数据库通过使用**行锁（row-level lock）[^ii]**来防止脏写；即当事务想要修改特定对象时，必须获取该对象的锁，然后必须持有该锁直到事务被提交或终止。这种锁定是读已提交模式（或更强的隔离级别）的数据库自动完成的。

> [^ii]: 行锁满足两阶段锁协议，2PL 是说：锁需要的时候才加上的，在事务结束的时候才释放；

:two: 无脏读保证：MVCC[^x] ，据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值。

> [^x]: 同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制；如下图中一个值从1按顺序修改为4的过程

<img src="./img/myl/07.jpg" width = 70% height = 70% alt="图片名称" align=center /> 



同时读已提交的隔离级别也会有一定的问题，比如出现不可重复读的情况，下面的例子：爱丽丝在银行有1000美元的储蓄，两个账户，每个500美元；现在一笔事务从她的一个账户中转移了100美元到另一个账户

* Alice在转账事务之前查询了账户1的金额为500元
* Alice在转账之后完成之后，查询了账户2的金额为400元
* 此时账户的总额为1000元，Alice就很疑惑为什么自己的钱少了？

<img src="./img/ddia/07.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

这种，这种异常被称为**不可重复读（nonrepeatable read）**，如果Alice在事务结束时再次读取账户1的余额，她将看到与她之前的查询中看到的不同的值（600美元）。在读已提交的隔离条件下，**不可重复读**可能会发生

#### 30 实现快照隔离

快照隔离和读已提交一致，使用写锁来防止脏读，也就是正在进行写入的事务会阻止另外一个事务修改同一个对象。

读取没有任何的锁定，**写不阻塞读，读不阻塞写**，RC下也是，数据库使用 **多版本并发控制（MVCC, multi-version concurrentcy control）** 数据库必须可能保留一个对象的几个不同的提交版本。另外使用MVCC实现快照隔离的存储引擎通常也会使用MVCC来实现读已提交（一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本）。

可以看下面这个PostgreSQL的例子：

<img src="./img/ddia/08.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

那么我们再来看一下一致性快照的可见性规则：也就是说当一个事务从数据库中读取时，事务ID用于决定它可以看见哪些对象，看不见哪些对象。规则如下：

1. 在每次事务开始时，数据库列出当时所有其他（尚未提交或中止）的事务清单，即使之后提交了，这些事务的写入也都会被忽略。
2. 被中止事务所执行的任何写入都将被忽略。
3. 由具有较晚事务ID（即，在当前事务开始之后开始的）的事务所做的任何写入都被忽略，而不管这些事务是否已经提交。
4. 所有其他写入，对应用都是可见的。

快照隔离和可重复读是同样的一个隔离级别。

#### 31 丢失更新 & 写偏差 

前面描述的是读-写并发场景下，只读事务在并发写入时候能看到什么，另外一个问题是两个事务并发写入的问题，即写-写冲突。如下图就是丢失更新的例子。

<img src="./img/ddia/02.jpg" width = 90% height = 70% alt="图片名称" /> 

解决写-写冲突有很多方式，比如比较并设置（CAS）

```sql
UPDATE wiki_pages SET content = '新内容'
  WHERE id = 1234 AND content = '旧内容';
```

在MySQL中，使用当前读[^cr]的方式来处理写-写冲突，下图为RR隔离级别下，写-写冲突的例子。

> [^cr]: 更新数据是先读后写的，读只能读当前**已提交**的最新值，这就是当前读。下

<img src="./img/ddia/10.jpg" width = 100% height = 70% alt="图片名称" />



下面是写偏差的例子，描述的是一个医生轮班管理程序，医院有以下的要求：至少有一位医生在待命

现在Alice 和 Bob 两位值班医生都感觉到不适，决定请假：

<img src="./img/ddia/09.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

如果两个事务读取相同的对象，然后不同的事务可能更新不同的对象，则可能发生写偏差（写偏差包含丢失更新）。在多个事务更新同一个对象的特殊情况下，就会发生脏写或丢失更新（取决于时机） **防止写偏差需要使用序列化隔离级别。**

> 幻读会导致写偏差。快照隔离避免了只读事务中的幻读，但是无法避免读写事务中的幻读。从上面的例子来看，幻读的问题貌似是没有对象可以加锁。人为的引入锁对象的方式被称之为*物化冲突*。

我们来看看一个幻读的例子：

<img src="./img/ddia/11.jpg" width = 70% height = 70% alt="图片名称" align=center /> 

:one: 主事务，检测表中是否有 id 为 1 的记录，没有则插入，这是我们期望的正常业务逻辑

:two: 干扰事务，目的在于扰乱主事务 的正常的事务执行

我们看到，干扰事务率先执行了，主事务发生了幻读，因为主事务读取的状态并不能支持他的下一步逻辑，感觉看到了幻影。**一个事务中的写入改变另一个事务的搜索查询的结果，被称为幻读** ，在我们的例子中是干扰事务妨碍了主事务搜索结果。在MySQL中，使用间隙锁来处理幻读问题。

不可重复读侧重表达 读-读，幻读则是说 读-写，用写来证实读的是鬼影。

#### 序列化/串行化

对串行化的理解应当是这样的：一次只执行一个事务。设计用于单线程的系统有时候比支持并发的系统更好，因为它可以避免协调锁的开销。数据库的早期，数据库意图包含整个用户的活动流程，但是如今的web应用，一个事务不会跨越多个请求，事务会在同一个Http请求被提交。

#### 两阶段锁定-2PL

大约30年来，在数据库中只有一种广泛使用的序列化算法：**两阶段锁定（2PL，two-phase locking）**。两阶段锁定要求只要没有写入，就允许多个事务同时读取同一个对象。但对象只要有写入（修改或删除），就需要**独占访问（exclusive access）** 权限。锁可以处于共享模式，可以处于独占模式：

:one: 若事务要读取对象，则须先以共享模式获取锁。允许多个事务同时持有共享锁。但如果另一个事务已经在对象上持有排它锁，则这些事务必须等待。

:two: 若事务要写入一个对象，它必须首先以独占模式获取该锁。没有其他事务可以同时持有锁（无论是共享模式还是独占模式），所以如果对象上存在任何锁，该事务必须等待。

:three: 如果事务先读取再写入对象，则它可能会将其共享锁升级为独占锁。升级锁的工作与直接获得排他锁相同。

:four: 事务获得锁之后，必须继续持有锁直到事务结束（提交或中止）。这就是“两阶段”这个名字的来源：第一阶段（当事务正在执行时）获取锁，第二阶段（在事务结束时）释放所有的锁。

#### 谓词锁

谓词锁类似于共享/排它锁，但不属于特定的对象（例如，表中的一行），它属于所有符合某些搜索条件的对象，如：

```sql
select * from bookings
where room_id = 123 and
      end_time > '2018-01-01 12:00' and 
      start_time < '2018-01-01 13:00';
```

谓词锁限制访问：

:one: 如果事务A想要读取匹配某些条件的对象，就像在这个 `SELECT` 查询中那样，它必须获取查询条件上的**共享谓词锁（shared-mode predicate lock）**。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。

:two: 如果事务A想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B已经提交或中止后才能继续。

谓词锁的关键思想是，**谓词锁甚至适用于数据库中尚不存在，但将来可能会添加的对象（幻象）**

和快照隔离的区别在是：快照隔离中 读不阻塞写，写不阻塞读；2PL中，写阻塞读，读阻塞写。

#### 索引范围锁

谓词锁的弊端是性能不佳：**如果活跃事务持有很多锁，检查匹配的锁会非常耗时。**因此，大多数使用2PL的数据库实际上实现了索引范围锁（也称为**间隙锁（next-key locking）**），间隙锁是一种简化的近似版谓词锁。

比如在房间预订数据库中，您可能会在`room_id`列上有一个索引，并且/或者在`start_time` 和 `end_time`上有索引（否则前面的查询在大型数据库上的速度会非常慢）：

- 假设您的索引位于`room_id`上，并且数据库使用此索引查找123号房间的现有预订。现在数据库可以简单地将共享锁附加到这个索引项上，指示事务已搜索123号房间用于预订。
- 或者，如果数据库使用基于时间的索引来查找现有预订，那么它可以将共享锁附加到该索引中的一系列值，指示事务已经将12:00~13:00时间段标记为用于预定。

无论哪种方式，搜索条件的近似值都附加到其中一个索引上。现在，如果另一个事务想要插入，更新或删除同一个房间和/或重叠时间段的预订，则它将不得不更新索引的相同部分。在这样做的过程中，它会遇到共享锁，它将被迫等到锁被释放。这种方法能够有效防止幻读和写入偏差。

###  序列化快照隔离（SSI）

**可序列化快照隔离（SSI, serializable snapshot isolation）** 它提供了完整的可序列化隔离级别，但与快照隔离相比只有只有很小的性能损失。



### 总结

:one: 脏读: 一个客户端读取到另一个客户端尚未提交的写入。**读已提交**或更强的隔离级别可以防止脏读。

:two: 脏写: 一个客户端覆盖写入了另一个客户端尚未提交的写入。几乎所有的事务实现都可以防止脏写。

:three: 读取偏差（不可重复读）: 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。**快照隔离**经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。快照隔离通常使用**多版本并发控制（MVCC）** 来实现。

:four: 更新丢失: 两个客户端同时执行**读取-修改-写入序列**。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定（`SELECT FOR UPDATE`）。

:five: 写偏差: 一个事务读取一些东西，根据它所看到的值作出决定，并将决定写入数据库。但是，写作的时候，决定的前提不再是真实的。只有可序列化的隔离才能防止这种异常。

:six: 幻读 : 事务读取符合某些搜索条件的对象。另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入歪斜环境中的幻影需要特殊处理，例如索引范围锁定。弱隔离级别可以防止这些异常情况，但是让应用程序开发人员手动处理其他应用程序（例如，使用显式锁定）。只有可序列化的隔离才能防范所有这些问题。我们讨论了实现可序列化事务的三种不同方法：

:seven: 字面意义上的串行执行: 如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个CPU核上处理，这是一个简单而有效的选择。

:eight: 两阶段锁定: 数十年来，两阶段锁定一直是实现可序列化的标准方式，但是许多应用出于性能问题的考虑避免使用它。



## 共识

 构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。比如通过使用**事务** 这个抽象，应用可以假装没有崩溃（原子性），没有其他人同时访问数据库（隔离），存储设备是完全可靠的（持久性）。即使发生崩溃，竞态条件和磁盘故障，事务抽象隐藏了这些问题，因此应用不必担心它们。

同样的分布式系统最重要的抽象之一就是**共识（consensus）**：**就是让所有的节点对某件事达成一致**（非正式定义）。

>  分布式一致性模型  和事务的特性ACID中的一致性 ，隔离级别   的区别   :question:    
>
> ACID一致性的概念是，**对数据的一组特定陈述必须始终成立**。即**不变量（invariants）**
>
> 分布式一致性主要是关于：面对延迟和故障时，如何协调副本间的状态
>
> 
>
> 事务隔离的目的是为了，避免由于同时执行事务而导致的竞争状态，而分布式一致性主要是关于，面对延迟和故障时，如何协调副本间的状态。

#### 线性一致性

多数的数据库提供了最终一致性的保证（数据是最终收敛的）。最终一致性的问题是：如果你在同一个时刻问2个副本同样一个问题，可能得到不同的答案，**线性一一致性**尝试提供只有一个副本的假象（即：只有一个副本），线性一致性提供新鲜度保证（一个客户端完成写操作，所有client可以必须能看到最新的答案）。

> 线性一一致性和可序列化的区别 :question:
>
> 可序列化是事务的隔离性，它确保事务的执行是特定的顺序。
>
> 线性一致性是读取和写入寄存器（单个对象）的新鲜度保证，他不会将组合操作为事务。
>
>  一个数据库可以提供可串行性和线性一致性，这种组合称之为，单副本强可串行性（strong-1SR）,基于2阶段锁的可串行化实现，通常是线性一致的。可重复读不是线性一致的。

#### 线性一致性的作用

:one: 单主复制的系统中，领导选取

:two: 唯一性约束

#### 实现线性一致的系统

:one: 单主复制，可能线性一致

:two: 共识算法：线性一致

:three: 多主复制：非线性一致

#### CAP

有一种说法是： 一致性、可用性、分区容错性，三者只能选择其二，这种说法有一定的误导性。这里的*P*指的是网络分区[^v]，网络分区是一种故障，是一定会（概率事件）存在的，P不是一个可选项而是一个必选项，那么就有了

:a: CP : 在网络分区下一致但不可用 。若应用需要线性一致性，某些副本和其他副本断开连接，那么这些副本掉线时不能处理请求（单主复制+同步），请求必须等到网络问题解决，或直接返回错误。（无论哪种方式，服务都**不可用（unavailable）**

:b: AP : 在网络分区下可用但不一致 。应用不需要线性一致性，那么某个副本即使与其他副本断开连接，也可以独立处理请求（例如多主复制）。在这种情况下，应用可以在网络问题前保持可用，但其行为不是线性一致的。

> [^v]:网络分区区别于分区，分区是一种中将数据集划分为多块，以此来提升并发读写能力； 而网络分区是指节点彼此断开但是仍然活跃。

#### 因果顺序不是全序的

自然数集是全序的，如1,2,3；数学集合是偏序的，比如`{a,b}`  和 `{b,c}` 是没有办法比较大小的。线性一致是全序的，不存在任何并发，所有的操作在一条时间线上。因果关系是偏序的，存在着并发。

线性一致性强于因果一致性，但是性能不如因果一致性。

#### 序列号顺序

显示跟踪所有已读数据确保因果关系意味着巨大的额外开销，可以使用序列号或时间戳来排序事件，时间戳并不一定来自时钟，可以是一个逻辑时钟（自增计数器），单主复制的数据库中，主库为每个操作自增一个计数器，从库按照复制日子中出现的顺序来应用写操作，那么从库的状态始终是因果一致的。

#### 非因果序列号生成器

对于无主复制或者多主复制，如何生成序列号呢？有下面三种方式：

:one: 每个节点生成自己独立的一组序列号，如有2个节点，一个奇数一个偶数

:two: 将物理时钟附加到每个操作上，也许可以提供一个全序关系

:three: 预先分配序列区块号，如节点A是1-1000区块的所有权；节点B是1001-2000区块的所有权

三种共同的问题是：生成的序列号与因果关系不一致。兰伯特时间戳可以产生与因果关系一致的时间戳。

#### 兰伯特时间戳

（计数器，节点ID）$(counter, node ID)$ 组成 兰伯特时间戳，每个节点和每个客户端跟踪迄今为止所见到的最大**计数器**值，并在每个请求中包含这个最大计数器值。当一个节点收到最大计数器值大于自身计数器值的请求或响应时，它立即将自己的计数器设置为这个最大值。下面2条规则去判断：

:a: 如果你有两个时间戳，则**计数器**值大者是更大的时间戳

:b:  如果计数器值相同，则节点ID越大的，时间戳越大



<img src="./img/ddia/12.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

其中客户端 A 从节点2 接收计数器值 `5` ，然后将最大值 `5` 发送到节点1 。此时，节点1 的计数器仅为 `1` ，但是它立即前移至 `5` ，所以下一个操作的计数器的值为 `6` 。



 虽然兰伯特时间戳定义了一个与因果一致的全序，但它还不足以解决分布式系统中的许多常见问题，比如确保用户名能唯一标识用户帐户的系统，你得搜集所有相同用户名的兰伯特时间戳，才能比较他们的时间戳，节点无法马上决定当前请求失败还是成功。所以仅知道全序是不够的，还需要知道全序何时结束。

#### 全序广播(原子广播)

全序广播通常被描述为在节点间交换消息的协议。 非正式地讲，它要满足两个安全属性：

:one: 可靠交付（reliable delivery）:  没有消息丢失：如果消息被传递到一个节点，它将被传递到所有节点。

:two: 全序交付（totally ordered delivery）:  消息以相同的顺序传递给每个节点。

正确的全序广播算法必须始终保证可靠性和有序性，即使节点或网络出现故障。当然在网络中断的时候，消息是传不出去的，但是算法可以不断重试，以便在网络最终修复时，消息能及时通过并送达。

可以使用全序广播来实现可序列化的事务，由于具备上诉2个安全属性，数据库的分区和副本就可以相互保持一致。*节点得到了共识*。

> :a: **全序广播等于共识**。
>
> :b: **线性一致的CAS等于共识。**



## 分布式事务与共识

共识的目标只是**让几个节点达成一致（get serveral nodes to agree on something）**。节点达成一致（共识）的应用场景：

:one: 领导选取；如在单主复制中，如果有2个以上领导就会有发生脑裂情况，脑裂时都2主都会接收写入，导致数据不一致或数据丢失

:two: 原子提交：在跨多节点或跨多分区事务的数据库中，所有节点必须就：一个事务是否成功 这件事达成一致（要不都成功；要不都失败）。

:three: 

2PC是一个最简单的共识算法，更好的一致性算法比如ZooKeeper（Zab）和etcd（Raft）中使用的算法；

#### 原子提交和2PC

对于多对象事务及维护次级索引的数据库，原子提交可以防止失败的事务搅乱数据库，避免数据库陷入半成品结果和半更新状态；对于单对象的原子性一般时都由数据库（存储引擎）本身保证。

**两阶段提交（two-phase commit）**是一种用于实现跨多个节点的原子事务提交的算法，即确保所有节点提交或所有节点中止。

<img src="./img/ddia/13.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

2PC使用一个通常不会出现在单节点事务中的新组件：**协调者（coordinator）**（也称为**事务管理器（transaction manager）**）。2PC事务以应用在多个数据库节点上读写数据开始。我们称这些数据库节点为**参与者（participants）**。当应用准备提交时，协调者开始阶段 1 ：它发送一个**准备（prepare）**请求到每个节点，询问它们是否能够提交。然后协调者会跟踪参与者的响应：

- 如果所有参与者都回答“是”，表示它们已经准备好提交，那么协调者在阶段 2 发出**提交（commit）**请求，然后提交真正发生。
- 如果任意一个参与者回复了“否”，则协调者在阶段2 中向所有节点发送**中止（abort）**请求。

具体的流程如下：

:one: 当应用想要启动一个分布式事务时，它向协调者请求一个事务ID。此事务ID是全局唯一的。

:two: 应用在每个参与者上启动单节点事务，并在单节点事务上捎带上这个全局事务ID。

:three: 当应用准备提交时，协调者向所有参与者发送一个**准备**请求，并打上全局事务ID的标记。如果任意一个请求失败或超时，则协调者向所有参与者发送针对该事务ID的中止请求。

:four: 参与者收到准备请求时，需要确保在任意情况下都的确可以提交事务。这包括将所有事务数据写入磁盘（出现故障，电源故障，或硬盘空间不足都不能是稍后拒绝提交的理由）以及检查是否存在任何冲突或违反约束。通过向协调者回答“是”，节点承诺，只要请求，这个事务一定可以不出差错地提交。换句话说，参与者放弃了中止事务的权利，但没有实际提交。

:five: 当协调者收到所有准备请求的答复时，会就提交或中止事务作出明确的决定（只有在所有参与者投赞成票的情况下才会提交）。协调者必须把这个决定写到磁盘上的事务日志中，如果它随后就崩溃，恢复后也能知道自己所做的决定。这被称为**提交点（commit point）**。

:six:一旦协调者的决定落盘，提交或放弃请求会发送给所有参与者。如果这个请求失败或超时，协调者必须永远保持重试，直到成功为止。没有回头路：如果已经做出决定，不管需要多少次重试它都必须被执行。如果参与者在此期间崩溃，事务将在其恢复后提交——由于参与者投了赞成，因此恢复后它不能拒绝提交。

下图是MySQL的两阶段提交过程。

<img src="./img/myl/03.jpg" width = "50%" height = "70%" alt="图片名称" align=center /> 

#### 协调者失效

上述第:three:步中很协调者发送“准备”请求之前失败，参与者可以安全的终止事务；在第:five: 步中如果任何提交和终止请求失败，协调者将无条件重试，但是协调者崩溃，参与者就什么也做不了只能等待。参与者的这这种事务状态称为：**存疑或者不确定**。

<img src="./img/ddia/14.jpg" width = 80% height = 70% alt="图片名称" align=center /> 

上图中：协调者实际上决定提交，数据库2 收到提交请求。但是，协调者在将提交请求发送到数据库1 之前发生崩溃，因此数据库1 不知道是否提交或中止。这里即便**超时**， 也是没用的。

* 如果数据库1 在超时后单方面中止，它将最终与执行提交的数据库2 不一致
* 单方面提交也是不安全的，因为另一个参与者可能已经中止了

此时完成2PC的唯一方法是等待协调者恢复，因此，协调者必须在向参与者发送提交或中止请求之前，将其提交或中止决定写入磁盘上的事务日志，协调者恢复后，通过读取其事务日志来确定所有存疑事务的状态。任何在协调者日志中没有提交记录的事务都会中止。

> 区分两种的不同的分布式事务
>
> :one: 数据库内部的分布式事务， 一些分布式数据库（即在其标准配置中使用复制和分区的数据库）支持数据库节点之间的内部事务，比如MySQL Cluster的NDB存储引擎就有这样的内部事务支持。此情形下，所有参与事务的节点都运行相同的软件。
>
> :two: 异构分布式事务：在异构事务中，参与者是2或者或者以上的技术，比如来自不同供应商的2个数据库/消息代理，跨系统的分布式事务需要保证原子提交。

#### 恰好一次的消息处理

异构的分布式事务能够集成两种不同的系统，比如当用于处理消息的数据库事务成功提交后，消息队列中的一条消息可以被认为已处理。如果消息或者数据库事务任意一者失败，2者都会终止，而消息代理可能会在稍后安全的重传消息。通过这种方式，可以确保消息被有效地恰好处理一次。

#### XA事务

扩展架构（eXtended Architecture） 是跨异构技术实现两阶段提交的标准。许多关系型数据库（PostgresSQL、MySQL、SQL Server、Oracle) 和消息代理（包括ActiveMQ，HornetQ，MSMQ和IBM MQ） 都支持XA。

### 共识

>  共识的定义：一个或多个节点可以**提议（propose）**某些值，而共识算法**决定（decides）**采用其中的某个值。
>
> 共识算法需要满足以下性质：
>
> :one: 一致同意：没有2个节点的决定不同
>
> :two: 完整性：没有节点决定2次
>
> :three: 有效性：如果一个节点决定了值`v`,则`v`由某个节点所提议
>
> :four: 终止 ： 由所有未崩溃的节点来最终决定值

终止属性形成了容错的思想，该属性是一个活性属性，而另外三个是安全属性。如果不关心容错，仅仅满足前三个属性就OK，比如2PC就能够满足，但是2PC的问题是，协调者失效，存疑的参与者无法决定是提交还是终止。

#### 共识算法和全序广播

最著名的容错共识算法是**视图戳复制（VSR, viewstamped replication）**，Paxos，Raft 以及 Zab。视图戳复制，Raft和Zab直接实现了全序广播，因为这样做比重复**一次一值（one value a time）**的共识更高效，因为全序广播的要求是：

> :one: 可靠交付（reliable delivery）:  没有消息丢失：如果消息被传递到一个节点，它将被传递到所有节点。
>
> :two: 全序交付（totally ordered delivery）:  消息以相同的顺序传递给每个节点。

等于进行了多轮共识。

在单主复制中，将所有的写入操作都交给主库，并以相同的顺序将他们应用到从库，从而使副本保持在最新状态，这里其实是一种**“独裁类型”**的共识算法，领导者是运维指定的，一旦故障必须人为干预，它无法满足共识算法的终止属性。

#### 时代编号和法定人数

共识协议一般会定义1个**时代编号（epoch number）**（在Paxos中称为**投票编号（ballot number）**，视图戳复制中的**视图编号（view number）**，以及Raft中的**任期号码（term number）**），并确保在每个时代中，领导者都是唯一的。每次领导者被认为挂掉的时候，会产生全序且单调递增的新的时代编号，更高时代编号的领导才真的领导。



节点在做出决定之前对提议进行投票的过程是一种同步复制，这是共识的局限性。



### 总结：

广泛的一系列问题实际上都可以归结为共识问题，并且彼此等价（从这个意义上来讲，如果你有其中之一的解决方案，就可以轻易将它转换为其他问题的解决方案）。这些等价的问题包括：

:one: **线性一致性的CAS寄存器**:  寄存器需要基于当前值是否等于操作给出的参数，原子地**决定**是否设置新值。

:two: **原子事务提交** :  数据库必须**决定**是否提交或中止分布式事务。

:three:  **全序广播**:  消息系统必须**决定**传递消息的顺序。

:four: **锁和租约**:  当几个客户端争抢锁或租约时，由锁来**决定**哪个客户端成功获得锁。

:five: **成员/协调服务**: 给定某种故障检测器（例如超时），系统必须**决定**哪些节点活着，哪些节点因为会话超时需要被宣告死亡。

:six: **唯一性约束**: 当多个事务同时尝试使用相同的键创建冲突记录时，约束必须**决定**哪一个被允许，哪些因为违反约束而失败。

如果你只有一个节点，或者你愿意将决策的权能分配给单个节点，所有这些事都很简单。这就是在单领导者数据库中发生的事情：所有决策权归属于领导者，这就是为什么这样的数据库能够提供线性一致的操作，唯一性约束，完全有序的复制日志，以及更多。但如果该领导者失效，或者如果网络中断导致领导者不可达，这样的系统就无法取得任何进展。应对这种情况可以有三种方法：

>  :one:等待领导者恢复，接受系统将在这段时间阻塞的事实。许多XA/JTA事务协调者选择这个选项。这种方法并不能完全达成共识，因为它不能满足**终止**属性的要求：如果领导者续命失败，系统可能会永久阻塞。
>
> :two: 人工故障切换，让人类选择一个新的领导者节点，并重新配置系统使之生效，许多关系型数据库都采用这种方方式。这是一种来自“天意”的共识 —— 由计算机系统之外的运维人员做出决定。故障切换的速度受到人类行动速度的限制，通常要比计算机慢（得多）。
>
> :three: 使用算法自动选择一个新的领导者。这种方法需要一种共识算法，使用成熟的算法来正确处理恶劣的网络条件是明智之举.







 









##### 

























# 衍生数据

从高层次看，存储和记录数据系统分为2大类：

* 记录系统（System of record） ：[数据的权威版本](如果其他系统和**记录系统**之间存在任何差异，那么记录系统中的值是正确的)
* 衍生数据系统（Derived data systems） ：可以理解为以数据为输入得到的输出数据

三种不同的系统：

* 服务（在线系统）
* 批处理系统（离线系统）
* 流处理系统（准实时系统）

讲述Unix哲学。

[MPP数据库](大规模并行处理（MPP， massively parallel processing)专注于在一组机器上并行执行分析SQL查询，而MapReduce和分布式文件系统【19】的组合则更像是一个可以运行任意程序的通用操作系统,批处理框架看起来越来越像MPP数据库了



